[
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Clara",
    "section": "Overview",
    "text": "Overview\nThis report provides a fully reproducible pipeline for processing [] using the R programming language."
  },
  {
    "objectID": "index.html#problem",
    "href": "index.html#problem",
    "title": "Clara",
    "section": "Problem",
    "text": "Problem"
  },
  {
    "objectID": "index.html#data-availability",
    "href": "index.html#data-availability",
    "title": "Clara",
    "section": "Data Availability",
    "text": "Data Availability"
  },
  {
    "objectID": "index.html#methods",
    "href": "index.html#methods",
    "title": "Clara",
    "section": "Methods",
    "text": "Methods\nSource of Data\nThe data used in this report come from the following sources:\n\n\nFederal Revenue Service: CNPJ database\n\nData Munging\nThe data munging followed the data science workflow outlined by Wickham et al. (2023), as illustrated in Figure 1. All processes were made using the Quarto publishing system (Allaire et al., n.d.), the R programming language (R Core Team, n.d.) and several R packages.\nSpatial data processing was performed using the terra R package (Hijmans, n.d.). For data manipulation and workflow, packages from the tidyverse and rOpenSci ecosystems—adhering to the tidy tools manifesto (Wickham, 2023)—were prioritized. All steps were designed to ensure transparency and reproducibility of results.\n\n\nFigure 1: Data science workflow created by Wickham, Çetinkaya-Runde, and Grolemund.\n\n\nSource: Reproduced from Wickham et al. (2023).\n\n\n\nCode Style\nThe Tidyverse code style guide and design principles were followed to ensure consistency and enhance readability.\nReproducibility\nThe pipeline is fully reproducible and can be run again at any time. See the README file in the code repository to learn how to run it."
  },
  {
    "objectID": "index.html#set-the-environment",
    "href": "index.html#set-the-environment",
    "title": "Clara",
    "section": "Set the Environment",
    "text": "Set the Environment\n\nlibrary(brandr)\nlibrary(beepr)\nlibrary(cli)\nlibrary(dplyr)\nlibrary(fs)\nlibrary(ggplot2)\nlibrary(groomr) # github.com/danielvartan/groomr\nlibrary(here)\nlibrary(magrittr)\nlibrary(osfr)\nlibrary(purrr)\nlibrary(stringr)\nlibrary(terra)\nlibrary(tidyterra)\nlibrary(readr)\nlibrary(tools)\nlibrary(utils)"
  },
  {
    "objectID": "index.html#claras-code",
    "href": "index.html#claras-code",
    "title": "Clara",
    "section": "Clara’s code",
    "text": "Clara’s code\n\nSections indicated in brackets (e.g., [Download Data]) reflect adaptations made by Daniel to Clara’s original code.\nAdditional modifications are noted directly in the code comments.\nThis code will be refactored in future updates.\n\n[Set Environment]\n\nlibrary(curl)\n#&gt; Using libcurl 8.16.0 with OpenSSL/3.5.3\n#&gt; \n#&gt; Attaching package: 'curl'\n#&gt; The following object is masked from 'package:readr':\n#&gt; \n#&gt;     parse_date\nlibrary(data.table)\n#&gt; \n#&gt; Attaching package: 'data.table'\n#&gt; The following object is masked from 'package:terra':\n#&gt; \n#&gt;     shift\n#&gt; The following object is masked from 'package:purrr':\n#&gt; \n#&gt;     transpose\n#&gt; The following objects are masked from 'package:dplyr':\n#&gt; \n#&gt;     between, first, last\nlibrary(dplyr)\nlibrary(fs)\nlibrary(geocodebr)\nlibrary(here)\nlibrary(httr2)\n#&gt; \n#&gt; Attaching package: 'httr2'\n#&gt; The following object is masked from 'package:xml2':\n#&gt; \n#&gt;     url_parse\nlibrary(purrr)\nlibrary(readr)\nlibrary(rutils) # github.com/danielvartan/rutils\n#&gt; \n#&gt; Attaching package: 'rutils'\n#&gt; The following object is masked from 'package:tidyterra':\n#&gt; \n#&gt;     drop_na\n#&gt; The following object is masked from 'package:base':\n#&gt; \n#&gt;     mode\nlibrary(rvest)\n#&gt; \n#&gt; Attaching package: 'rvest'\n#&gt; The following object is masked from 'package:readr':\n#&gt; \n#&gt;     guess_encoding\nlibrary(sf)\n#&gt; Linking to GEOS 3.13.1, GDAL 3.11.3, PROJ 9.6.0; sf_use_s2() is TRUE\nlibrary(stringr)\nlibrary(tidyr)\n#&gt; \n#&gt; Attaching package: 'tidyr'\n#&gt; The following object is masked from 'package:rutils':\n#&gt; \n#&gt;     drop_na\n#&gt; The following object is masked from 'package:terra':\n#&gt; \n#&gt;     extract\n#&gt; The following object is masked from 'package:magrittr':\n#&gt; \n#&gt;     extract\nlibrary(tools)\nlibrary(utils)\nlibrary(zip)\n#&gt; \n#&gt; Attaching package: 'zip'\n#&gt; The following objects are masked from 'package:utils':\n#&gt; \n#&gt;     unzip, zip\n\n\n# Definir diretorio com arquivos de CNPJ\n\ncnpj_dir &lt;- here(\"data-raw\") # \"1-inputs/CNPJ_2024\"\n\n\n# Definir caminhos dos diretorios\nestabelecimentos_dir &lt;- here(cnpj_dir, \"1-ESTABELECIMENTOS\")\nempresas_dir &lt;- here(cnpj_dir, \"2-EMPRESAS\")\nsocios_dir &lt;- here(cnpj_dir, \"3-SOCIOS\")\ndemais_arquivos_dir &lt;- here(cnpj_dir, \"4-DEMAIS_ARQUIVOS\")\ntemporario_dir &lt;- here(cnpj_dir, \"5-TEMPORARIO\")\n\n[Download Data]\n\nPara dar proceguinto ao codigo, baixar todos os arquivos da Receita Federal do Brasil.\n\nMês de referência: 2025-01 (janeiro de 2025)\nURL: https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj/?C=N;O=D\nArmazenar arquivos em CNPJ_2024 dentro de diretorio “inputs”\n\n\n\ndata_raw_dir &lt;- here(\"data-raw\")\n\nif (!dir_exists(data_raw_dir)) dir_create(data_raw_dir)\n\n\nroot &lt;- file.path(\n    \"https://arquivos.receitafederal.gov.br\",\n    \"dados\",\n    \"cnpj\",\n    \"dados_abertos_cnpj\"\n  )\n\n\nurls &lt;- character()\n\nfor (i in seq_len(1)) { # for (i in seq_len(12)) {\n  i_path &lt;-\n    root |&gt;\n    file.path(paste0(\"2025-\", stringr::str_pad(i, 2, pad = 0)))\n\n  urls &lt;-\n    i_path |&gt;\n    read_html() |&gt;\n    html_elements(\"a\") |&gt;\n    html_attr(\"href\") |&gt;\n    str_subset(\"\\\\.zip$\") %&gt;%\n    file.path(i_path, .) |&gt;\n    append(x = urls, values =_, after = length(urls))\n}\n\n\nurls |&gt;\n  map_dbl(.f = get_file_size, .progress = TRUE) |&gt;\n  sum() |&gt;\n  as_fs_bytes()\n\n\nurls |&gt; download_file(dir = data_raw_dir)\n\nbeep()\n\n01.01-preparar_arquivos_cnpj.R\n\nEm todos os arquivos do site passam por unzip e são organizados em pastas.\n\nDescompactar Arquivos de CNPJ e Organizá-los em Diretórios\n\nDefinir subdiretórios.\n\n\nsubdiretorios &lt;- c(\n  \"1-ESTABELECIMENTOS\",\n  \"2-EMPRESAS\",\n  \"3-SOCIOS\",\n  \"4-DEMAIS_ARQUIVOS\"\n)\n\n\nCriar subdiretórios no diretório caso nao existam.\n\n\nfor (subdir in subdiretorios) {\n  caminho &lt;- file.path(cnpj_dir, subdir)\n\n  # Verificar se o diretorio existe\n  if (!file.exists(caminho)) {\n    dir.create(caminho, recursive = TRUE)\n    cat(\"Diretorio criado:\", caminho, \"\\n\")\n  } else {\n    cat(\"Diretorio ja existe:\", caminho, \"\\n\")\n  }\n}\n#&gt; Diretorio ja existe: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS \n#&gt; Diretorio ja existe: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS \n#&gt; Diretorio ja existe: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS \n#&gt; Diretorio ja existe: /home/danielvartan/Git/acessosan/data-raw/4-DEMAIS_ARQUIVOS\n\n\n# Definir diret?rios de destino para extra??o\ndiretorios_destino &lt;- list(\n  \"Estabelecimentos\" = file.path(cnpj_dir, \"1-ESTABELECIMENTOS\"),\n  \"Empresas\" = file.path(cnpj_dir, \"2-EMPRESAS\"),\n  \"Socios\" = file.path(cnpj_dir, \"3-SOCIOS\"),\n  \"Demais_Arquivos\" = file.path(cnpj_dir, \"4-DEMAIS_ARQUIVOS\")\n)\n\n\nDefinir função para descompactar os arquivos.\n\n\nunzip_arquivos &lt;- function() {\n  arquivos_zip &lt;- list.files(cnpj_dir, pattern = \"\\\\.zip$\", full.names = TRUE, recursive = TRUE)\n\n  for (zip_file_path in arquivos_zip) {\n    # Define o diretorio de destino baseado no nome do arquivo zip\n    file_name &lt;- basename(zip_file_path)\n    if (grepl(\"^Estabelecimentos\", file_name)) {\n      destino &lt;- diretorios_destino$Estabelecimentos\n    } else if (grepl(\"^Empresas\", file_name)) {\n      destino &lt;- diretorios_destino$Empresas\n    } else if (grepl(\"^Socios\", file_name)) {\n      destino &lt;- diretorios_destino$Socios\n    } else {\n      destino &lt;- diretorios_destino$Demais_Arquivos\n    }\n\n    # Cria o diretorio de destino se nao existir\n    if (!dir.exists(destino)) {\n      dir.create(destino, recursive = TRUE)\n    }\n\n    # (Daniel) Using the `zip` package for an OS-independent solution\n    zip_file_path |&gt; unzip(, exdir = destino)\n\n    # Extracao do conteudo do arquivo .zip\n    # unzip(zip_file_path, exdir = destino)\n    cat(\"Arquivos de\", file_name, \"extra?dos para\", destino, \"\\n\")\n  }\n}\n\n\n# Descompactar e organizar arquivos .zip\nunzip_arquivos()\n\nbeep()\n\n01.02-filtrar_base_cnpj.R\n\nEm que cada arquivo de CNPJ é filtrado pelos códigos de atividade econômica “4771701” e “4771702” (farmácias), e para cidade de São Paulo (código 7107).\nNota: A receita federal usa um código de municípios próprio e a conversão para códigos do IBGE se encontra aqui. Nessa etapa, são processados os arquivos de estabelecimentos do CNPJ.\n\nFiltrar Arquivo de Estabelecimentos da Base de CNPJ\n\nDefinir caminhos dos diretórios.\n\n\noutput_dir &lt;- file.path(temporario_dir, \"01.02-filtrar_base\")\n\n\n# Criar diretorio de saída caso nao exista\nif (!dir.exists(output_dir)) {\n  dir.create(output_dir, recursive = TRUE)\n}\n\nSelecionar Estabelecimentos da UF São Paulo e com CNAEs Específicos\n\nDefinir CNAEs para a filtragem.\n\n\ncnaes_lista &lt;- c(\"4771701\", \"4771702\")\n\n\nDefinir município de interesse (São Paulo).\n\n\nsp_mun &lt;- 7107\n\n\nCriar uma lista para armazenar os data frames.\n\n\ndados &lt;- list()\n\n\nListar arquivos no diretorio de estabelecimentos.\n\n\narquivos_estab &lt;- list.files(estabelecimentos_dir, full.names = TRUE)\n\n\nIterar sobre os arquivos e processá-los.\n\n\nfor (caminho_arquivo in arquivos_estab) {\n  cat(\"Processando:\", caminho_arquivo, \"\\n\")\n\n  tryCatch({\n    # Ler o arquivo CSV\n    estab &lt;- fread(caminho_arquivo, sep = \";\", encoding = \"Latin-1\", header = FALSE, col.names = c(\n      \"CNPJ_BASICO\",\n      \"CNPJ_ORDEM\",\n      \"CNPJ_DV\",\n      \"IDENTIFICADOR_MATRIZ_FILIAL\",\n      \"NOME_FANTASIA\",\n      \"SITUACAO_CADASTRAL\",\n      \"DATA_SITUACAO_CADASTRAL\",\n      \"MOTIVO_SITUACAO_CADASTRAL\",\n      \"NOME_CIDADE_EXTERIOR\",\n      \"PAIS\",\n      \"DATA_INICIO_ATIVIDADE\",\n      \"CNAE_FISCAL_PRINCIPAL\",\n      \"CNAE_FISCAL_SECUNDARIO\",\n      \"TIPO_LOGRADOURO\",\n      \"LOGRADOURO\",\n      \"NUMERO\",\n      \"COMPLEMENTO\",\n      \"BAIRRO\",\n      \"CEP\",\n      \"UF\",\n      \"MUNICIPIO_TOM\",\n      \"DDD_1\",\n      \"TELEFONE_1\",\n      \"DDD_2\",\n      \"TELEFONE_2\",\n      \"DDD_FAX\",\n      \"FAX\",\n      \"CORREIO_ELETRONICO\",\n      \"SITUACAO_ESPECIAL\",\n      \"DATA_SITUACAO_ESPECIAL\"\n    ))\n\n    # Converter colunas para os tipos adequados\n    estab &lt;- estab %&gt;%\n      mutate(\n        CNAE_FISCAL_PRINCIPAL = as.character(CNAE_FISCAL_PRINCIPAL),\n        CEP = as.character(CEP),\n        UF = as.character(UF),\n        MUNICIPIO_TOM = as.integer(MUNICIPIO_TOM),\n        DDD_1 = as.character(DDD_1),\n        TELEFONE_1 = as.character(TELEFONE_1),\n        DDD_2 = as.character(DDD_2),\n        TELEFONE_2 = as.character(TELEFONE_2)\n      )\n\n    # Filtrar pelos CNAEs desejados\n    estab &lt;- estab[CNAE_FISCAL_PRINCIPAL %in% cnaes_lista]\n\n    # Filtrar pela UF (Sao Paulo)\n    estab &lt;- estab[MUNICIPIO_TOM == sp_mun]\n\n    cat(\"Processado:\", caminho_arquivo, \"\\n\")\n\n    # Adicionar o data frame a lista\n    dados &lt;- append(dados, list(estab))\n  }, error = function(e) {\n    cat(\"Erro ao processar o arquivo\", caminho_arquivo, \":\", e$message, \"\\n\")\n  })\n}\n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y0.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y0.D50111.ESTABELE \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y1.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y1.D50111.ESTABELE \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y2.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y2.D50111.ESTABELE \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y3.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y3.D50111.ESTABELE \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y4.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y4.D50111.ESTABELE \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y5.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y5.D50111.ESTABELE \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y6.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y6.D50111.ESTABELE \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y7.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y7.D50111.ESTABELE \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y8.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y8.D50111.ESTABELE \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y9.D50111.ESTABELE \n#&gt; Processado: /home/danielvartan/Git/acessosan/data-raw/1-ESTABELECIMENTOS/K3241.K03200Y9.D50111.ESTABELE\n\nbeep()\n\n\nestab &lt;- rbindlist(dados, use.names = TRUE, fill = TRUE)\n\n\nSalvar o DataFrame processado.\n\n\nfwrite(estab, file.path(output_dir, \"01.02.01-estabelecimentos_spcap_farmacias.csv\"), sep = \";\", row.names = FALSE)\n\n01.03-filtrar_dados_empresas_socios.R\n\nEm que são integrados os dados de empresa e sócios de cada estabelecimento. Creio que tais etapas não serão necessárias se o foco for nos estabelecimentos.\n\nFiltrar Bases Empresas e Sócios\n\nDefinir caminhos dos diretórios.\n\n\noutput_dir &lt;- file.path(temporario_dir, \"01.03-filtrar_dados_empresas_socios\")\n\n\nCriar diretorio de saida caso não exista.\n\n\nif (!dir.exists(output_dir)) {\n  dir.create(output_dir, recursive = TRUE)\n}\n\n\nLer arquivo ‘01.02.01-estabelecimentos_spcap_farmacias.csv’ gerado na etapa 01.02.\n\n\nestab &lt;- fread(file.path(temporario_dir, \"01.02-filtrar_base/01.02.01-estabelecimentos_spcap_farmacias.csv\"), sep = \";\", encoding = \"Latin-1\")\n\n\nCriar uma lista para armazenar os data frames filtrados.\n\n\ndados_empresas &lt;- list()\n\n\nListar arquivos no diretorio de empresas.\n\n\narquivos_empresas &lt;- list.files(empresas_dir, full.names = TRUE)\n\n\nIterar sobre os arquivos e processá-los.\n\n\nfor (caminho_arquivo in arquivos_empresas) {\n  if (file.exists(caminho_arquivo)) {\n    cat(\"Processando:\", caminho_arquivo, \"\\n\")\n\n    tryCatch({\n      # Ler o arquivo CSV\n      empresas &lt;- fread(caminho_arquivo, sep = \";\", encoding = \"Latin-1\", header = FALSE, col.names = c(\n        \"CNPJ_BASICO\",\n        \"RAZAO_SOCIAL_NOME_EMPRESARIAL\",\n        \"NATUREZA_JURIDICA\",\n        \"QUALIFICACAO_RESPONSAVEL\",\n        \"CAPITAL_SOCIAL_EMPRESA\",\n        \"PORTE_EMPRESA\",\n        \"ENTE_FEDERATIVO_RESPONSAVEL\"\n      ))\n\n      # Converter tipos de colunas conforme necessario\n      empresas &lt;- empresas %&gt;%\n        mutate(\n          CNPJ_BASICO = as.integer(CNPJ_BASICO),\n          NATUREZA_JURIDICA = as.integer(NATUREZA_JURIDICA)\n        )\n\n      # Filtrar pelos CNPJs existentes em estab\n      empresas &lt;- empresas[CNPJ_BASICO %in% estab$CNPJ_BASICO]\n\n      # Adicionar o data frame à lista\n      dados_empresas &lt;- append(dados_empresas, list(empresas))\n\n    }, error = function(e) {\n      cat(\"Erro ao processar o arquivo\", caminho_arquivo, \":\", e$message, \"\\n\")\n    })\n  }\n}\n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y0.D50111.EMPRECSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y1.D50111.EMPRECSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y2.D50111.EMPRECSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y3.D50111.EMPRECSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y4.D50111.EMPRECSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y5.D50111.EMPRECSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y6.D50111.EMPRECSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y7.D50111.EMPRECSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y8.D50111.EMPRECSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/2-EMPRESAS/K3241.K03200Y9.D50111.EMPRECSV\n\nbeep()\n\n\nConcatenar todos os data frames da lista em um único data.table.\n\n\nempresas &lt;- rbindlist(dados_empresas, use.names = TRUE, fill = TRUE)\n\n\nSalvar o dataframe resultante.\n\n\nfwrite(empresas, file.path(output_dir, \"01.03.01-empresas_redepharma.csv\"), sep = \";\", row.names = FALSE)\n\n\nListar arquivos no diretório de sócios.\n\n\narquivos_socios &lt;- list.files(socios_dir, full.names = TRUE)\n\n\nCriar uma lista para armazenar os data frames filtrados.\n\n\ndados_socios &lt;- list()\n\n\nIterar sobre os arquivos e processá-los.\n\n\nfor (caminho_arquivo in arquivos_socios) {\n  if (file.exists(caminho_arquivo)) {\n    cat(\"Processando:\", caminho_arquivo, \"\\n\")\n\n    tryCatch({\n      # Ler o arquivo CSV\n      socios &lt;- fread(caminho_arquivo, sep = \";\", encoding = \"Latin-1\", header = FALSE, col.names = c(\n        \"CNPJ_BASICO\",\n        \"IDENTIFICADOR_SOCIO\",\n        \"NOME_SOCIO\",\n        \"CPF_CNPJ_SOCIO\",\n        \"QUALIFICACAO_SOCIO\",\n        \"DATA_ENTRADA_SOCIEDADE\",\n        \"PAIS\",\n        \"CPF_REPRESENTANTE\",\n        \"NOME_REPRESENTANTE\",\n        \"QAUALIFICACAO_REPRESENTANTE\",\n        \"FAIXA_ETARIA\"\n      ))\n\n      # Converter tipos de colunas conforme necessario\n      socios &lt;- socios %&gt;%\n        mutate(\n          CNPJ_BASICO = as.integer(CNPJ_BASICO))\n\n      # Filtrar pelos CNPJs existentes em estab\n      socios &lt;- socios[CNPJ_BASICO %in% estab$CNPJ_BASICO]\n\n      # Adicionar o data frame à lista\n      dados_socios &lt;- append(dados_socios, list(socios))\n\n    }, error = function(e) {\n      cat(\"Erro ao processar o arquivo\", caminho_arquivo, \":\", e$message, \"\\n\")\n    })\n  }\n}\n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y0.D50111.SOCIOCSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y1.D50111.SOCIOCSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y2.D50111.SOCIOCSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y3.D50111.SOCIOCSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y4.D50111.SOCIOCSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y5.D50111.SOCIOCSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y6.D50111.SOCIOCSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y7.D50111.SOCIOCSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y8.D50111.SOCIOCSV \n#&gt; Processando: /home/danielvartan/Git/acessosan/data-raw/3-SOCIOS/K3241.K03200Y9.D50111.SOCIOCSV\n\nbeep()\n\n\nConcatenar todos os data frames da lista em um único data.table.\n\n\nsocios &lt;- rbindlist(dados_socios, use.names = TRUE, fill = TRUE)\n\n\nSalvar o dataframe resultante.\n\n\nfwrite(\n  socios,\n  file.path(output_dir, \"01.03.02-socios_redepharma.csv\"),\n  sep = \";\",\n  row.names = FALSE\n)\n\n01.04-unir_estab_empresas_socios.R\nUnir Bases de Estabelecimentos — Empresas e Sócios\n\nDefinir caminhos dos diretórios.\n\n\noutput_dir &lt;- file.path(temporario_dir, \"01.04-unir_estab_empresas_socios\")\n\n\nCriar diretorio de saida caso não exista.\n\n\nif (!dir.exists(output_dir)) {\n  dir.create(output_dir, recursive = TRUE)\n}\n\n\nLer arquivos gerados nas etapas 01.02 e 01.03.\n\n\nestab &lt;- fread(file.path(temporario_dir, \"01.02-filtrar_base/01.02.01-estabelecimentos_spcap_farmacias.csv\"), sep = \";\", encoding = \"Latin-1\")\n\nempresas &lt;- fread(file.path(temporario_dir, \"01.03-filtrar_dados_empresas_socios/01.03.01-empresas_redepharma.csv\"), sep = \";\", encoding = \"Latin-1\")\n\nsocios &lt;- fread(file.path(temporario_dir, \"01.03-filtrar_dados_empresas_socios/01.03.02-socios_redepharma.csv\"), sep = \";\", encoding = \"Latin-1\")\n\n\nEditar dataframe sócios.\n\n\nsocios &lt;- socios %&gt;%\n  filter(!is.na(NOME_SOCIO) & !is.na(CPF_CNPJ_SOCIO)) %&gt;%\n  mutate(across(where(is.character), ~ gsub(\"\\\\*\", \"\", .))) %&gt;%  # Remover \"*\"\n  mutate(SOCIO_INFO = paste0(NOME_SOCIO, \" - \", CPF_CNPJ_SOCIO)) %&gt;%\n  group_by(CNPJ_BASICO) %&gt;%\n  mutate(SOCIO_NUM = row_number()) %&gt;%\n  ungroup() %&gt;%\n  select(CNPJ_BASICO, SOCIO_NUM, SOCIO_INFO) %&gt;%\n  pivot_wider(names_from = SOCIO_NUM, values_from = SOCIO_INFO, names_prefix = \"SOCIO_\", values_fill = list(SOCIO_INFO = \"NA\"))\n\n\nUnir estabelecimentos, empresas e sócios.\n\n\nestab_emp_soc &lt;- estab %&gt;%\n  left_join(empresas, by = \"CNPJ_BASICO\") %&gt;%\n  left_join(socios, by = \"CNPJ_BASICO\")\n\n\nSalvar o dataframe resultante.\n\n\nfwrite(estab_emp_soc, file.path(output_dir, \"01.04.01-estab_emp_soc_spcap_farmacias.csv\"), sep = \";\", row.names = FALSE)\n\n01.05-adicionar_informacoes_porte_traduzir_base.R\n\nEm que retirei os Microempreendedores Individuais da base, ainda adicionando porte empresarial e também “traduzindo” os códigos de município e e afins.\n\nAdicionar Informações de Porte Empresarial e Fazer Traduções na Base\n\nDefinir caminhos dos diretórios.\n\n\noutput_dir &lt;- file.path(\n  temporario_dir,\n  \"01 05-adicionar_informacoes_porte_traduzir_base\"\n)\n\n\nCriar diretório de saida caso não exista.\n\n\nif (!dir.exists(output_dir)) {\n  dir.create(output_dir, recursive = TRUE)\n}\n\n\n# Ler arquivo gerado na etapa 01.04\nestab_emp_soc &lt;-\n  file.path(\n    temporario_dir,\n    \"01.04-unir_estab_empresas_socios/01.04.01-estab_emp_soc_spcap_farmacias.csv\"\n  ) |&gt;\n    fread(sep = \";\", encoding = \"Latin-1\")\n\n\nLer arquivos de corespondência para Município, Natureza Jurídica e CNAE\nMunicípios\nBaixar correspondência com códigos do IBGE pelo link abaixo, na aba ‘Tabela de Órgãos e Municípios’\nhttps://dados.gov.br/dados/conjuntos-dados/tabela-de-rgos-e-municpios#:~:text=Info,RFB%20e%20dom%C3%ADnios%20de%20endere%C3%A7amento.\n\n\nDefinir nome do arquivo de correspondências para municípios.\n\n\nmunicipios_arquivo &lt;- \"https://www.gov.br/receitafederal/dados/municipios.csv\"\n\n\nLer arquivo de correspondência para municípios.\n\n\nmunicipios_trad &lt;- read.csv(municipios_arquivo, sep=\";\", fileEncoding = \"latin1\")\n\n\nCorrigir nomes das colunas.\n\n\ncolnames(municipios_trad) &lt;- gsub(\"\\\\.+\", \"_\", colnames(municipios_trad))\n\n\nSelecionar colunas que serão utilizadas.\n\n\nmunicipios_trad &lt;- municipios_trad[, c(\"CÓDIGO_DO_MUNICÍPIO_TOM\", \"CÓDIGO_DO_MUNICÍPIO_IBGE\", \"MUNICÍPIO_IBGE\")]\n\n\nRenomear colunas.\n\n\ncolnames(municipios_trad) &lt;- c(\"MUNICIPIO_TOM\", \"MUNICIPIO_IBGE\", \"MUNICIPIO\")\n\n\nNaturezas Jurídicas. Definir nome do arquivo de correspondências para Natureza Jurídica.\n\n\nnaturezas_juridicas_arquivo &lt;- \"F.K03200$Z.D50111.NATJUCSV\"\n\n\nLer arquivo de dados do Simples Nacional.\n\n\nnaturezas_juridicas_trad &lt;- read.csv(file.path(demais_arquivos_dir, naturezas_juridicas_arquivo), sep=\";\", fileEncoding = \"latin1\", header = FALSE)\n\n\nAtribuir nomes às colunas.\n\n\ncolnames(naturezas_juridicas_trad) &lt;- c(\"NATUREZA_JURIDICA\", \"DESCRICAO\")\n\n\nGarantir que “NATUREZA_JURIDICA” seja do tipo inteiro.\n\n\nnaturezas_juridicas_trad$NATUREZA_JURIDICA &lt;- as.integer(naturezas_juridicas_trad$NATUREZA_JURIDICA)\n\n\nCNAEs Definir nome do arquivo de correspondências para CNAEs\n\n\ncnaes_arquivo &lt;- \"F.K03200$Z.D50111.CNAECSV\"\n\n\nLer arquivo de dados do Simples Nacional\n\n\ncnaes_trad &lt;- read.csv(file.path(demais_arquivos_dir, cnaes_arquivo), sep=\";\", fileEncoding = \"latin1\", header = FALSE)\n\n\nAtribuir nomes às colunas.\n\n\ncolnames(cnaes_trad) &lt;- c(\"CNAE\", \"DESCRICAO\")\n\n\nGarantir que “CNAE” seja do tipo caractere (string).\n\n\ncnaes_trad$CNAE &lt;- as.character(cnaes_trad$CNAE)\n\nUnir ou Traduzir Conforme Correspondências\n\nUnir os dataframes para Municípios.\n\n\nestab_emp_soc &lt;- merge(estab_emp_soc, municipios_trad, by = \"MUNICIPIO_TOM\", all.x = TRUE)\nestab_emp_soc &lt;- subset(estab_emp_soc, select = -MUNICIPIO_TOM)\n\n\nCriar um dicionário de mapeamento {NATUREZA_JURIDICA: DESCRICAO}\n\n\nnaturezas_juridicas_dict &lt;- setNames(naturezas_juridicas_trad$DESCRICAO, naturezas_juridicas_trad$NATUREZA_JURIDICA)\n\n\nAplicar o mapeamento (tradução).\n\n\nestab_emp_soc$NATUREZA_JURIDICA &lt;- naturezas_juridicas_dict[as.character(estab_emp_soc$NATUREZA_JURIDICA)]\n\n\nTraduzir códigos de matriz e filial.\n\n\nestab_emp_soc$MATRIZ_FILIAL &lt;- recode(estab_emp_soc$IDENTIFICADOR_MATRIZ_FILIAL, `1` = \"Matriz\", `2` = \"Filial\")\nestab_emp_soc &lt;- subset(estab_emp_soc, select = -IDENTIFICADOR_MATRIZ_FILIAL)\n\n\nDefinir dicionário de mapeamento de situação cadastral.\n\n\nsituacao_map &lt;- setNames(c(\"Nula\", \"Ativa\", \"Suspensa\", \"Inapta\", \"Baixada\"), c(1, 2, 3, 4, 8))\n\n\nAplicar o mapeamento.\n\n\nestab_emp_soc$SITUACAO_CADASTRAL &lt;- recode(estab_emp_soc$SITUACAO_CADASTRAL, !!!situacao_map)\n\nListar CNPJs MEI e Simples\n\nDefinir nome do arquivo para o Simples Nacional\n\n\nsimples_arquivo &lt;- \"F.K03200$W.SIMPLES.CSV.D50111\"\n\n\nLer arquivo de dados do Simples Nacional.\n\n\nsimples &lt;-\n  file.path(demais_arquivos_dir, simples_arquivo) |&gt;\n  read.csv(\n    sep = \";\",\n    encoding = \"latin1\",\n    header = FALSE,\n    col.names = c(\n      \"CNPJ_BASICO\",\n      \"SIMPLES\",\n      \"DATA_OPCAO_SIMPLES\",\n      \"DATA_EXCLUSAO_SIMPLES\",\n      \"MEI\",\n      \"DATA_OPCAO_MEI\",\n      \"DATA_EXCLUSAO_MEI\"\n    )\n  )\n\nbeep()\n\n\nFiltrar dados do Simples.\n\n\nsimples &lt;- simples[simples$CNPJ_BASICO %in% estab_emp_soc$CNPJ_BASICO, ]\n\n\nListar CNPJ básicos do Simples Nacional.\n\n\ncnpj_simples &lt;- simples[simples$SIMPLES == \"S\", c(\"CNPJ_BASICO\", \"SIMPLES\")]\n\n\nSalvar o dataframe como CSV.\n\n\ndir &lt;- file.path(\n  temporario_dir,\n  \"01.05-adicionar_informacoes_porte_traduzir_base\"\n)\n\nif (!dir.exists(dir)) dir.create(dir)\n\n\ncnpj_simples |&gt;\n  write.csv(\n    file.path(\n      temporario_dir,\n      \"01.05-adicionar_informacoes_porte_traduzir_base\",\n      \"01.05.01-simples_spcap_farmacias.csv\"\n    ),\n    row.names = FALSE\n  )\n\n\nListar CNPJ básicos Microempreendedores Individuais.\n\n\ncnpj_mei &lt;- simples[simples$MEI == \"S\", c(\"CNPJ_BASICO\", \"MEI\")]\n\n\nSalvar o dataframe como CSV.\n\n\nwrite.csv(cnpj_simples, file.path(temporario_dir,\n                                  '01.05-adicionar_informacoes_porte_traduzir_base/01.05.02-mei_spcap_farmacias.csv'), row.names = FALSE)\n\n\nUnir ‘cnpj_completo’ resultante com ‘cnpj_simples’.\n\n\nestab_emp_soc &lt;- merge(estab_emp_soc, cnpj_simples, by = \"CNPJ_BASICO\", all.x = TRUE)\n\n\nUnir ‘cnpj_completo’ resultante com ‘cnpj_mei’.\n\n\nestab_emp_soc &lt;- merge(estab_emp_soc, cnpj_mei, by = \"CNPJ_BASICO\", all.x = TRUE)\n\nCorrigir Valores de Capital Social e Porte\n\nTratar a coluna CAPITAL_SOCIAL_EMPRESA.\n\n\nestab_emp_soc$CAPITAL_SOCIAL_EMPRESA &lt;- estab_emp_soc$CAPITAL_SOCIAL_EMPRESA %&gt;%\n  gsub(\"\\\\.\", \"\", .) %&gt;%  # Remover separadores de milhar\n  gsub(\",\", \".\", .) %&gt;%   # Trocar vírgula decimal por ponto\n  as.numeric()            # Converter para número\n\n\nCriar dicionário de mapeamento.\n\n\nporte_map &lt;- setNames(c(\"Não informado\", \"Microempresa\", \"Empresa de pequeno porte\", \"Demais portes\"),\n                      c(0, 1, 3, 5))\n\n\nSubstituir os valores da coluna PORTE_EMPRESA.\n\n\nestab_emp_soc$PORTE_EMPRESA &lt;- recode(estab_emp_soc$PORTE_EMPRESA, !!!porte_map)\n\n\nSubstituir “PORTE_EMPRESA” por “MEI” onde “MEI” é igual a “S”.\n\n\nestab_emp_soc$PORTE_EMPRESA[estab_emp_soc$MEI == \"S\"] &lt;- \"MEI\"\nestab_emp_soc &lt;- subset(estab_emp_soc, select = -MEI)\n\n\nSalvar arquivo gerado.\n\n\nwrite.csv(estab_emp_soc, file.path(temporario_dir,\n                                  '01.05-adicionar_informacoes_porte_traduzir_base/01.05.03-estab_emp_soc_trad_spcap_farmacias.csv'), row.names = FALSE)\n\n01.06-geocodificar_enderecos.R\n\nEm que utilizo o pacote geocodebr do IPEA para geocodificar os endereços. É provável que devam ser feitas algumas correções nessa etapa frente às atualizações do pacote.\n\n\noutput_dir &lt;- file.path(temporario_dir, \"01.06-geocodificar_enderecos\")\n\n\nCriar diretorio de saida caso não exista.\n\n\nif (!dir.exists(output_dir)) {\n  dir.create(output_dir, recursive = TRUE)\n}\n\n\nLer 01.05.03 arquivo gerado na etapa 01.05.\n\n\nestab_emp_soc &lt;-\n  file.path(\n    temporario_dir,\n    \"01.05-adicionar_informacoes_porte_traduzir_base\",\n    \"01.05.03-estab_emp_soc_trad_spcap_farmacias.csv\"\n  ) |&gt;\n  read.csv(sep = \",\", encoding = \"Latin-1\")\n\nTratar Dados para Geocodificar\n\nAdicionar 0s nos CEPs com menos de 8 dígitos.\n\n\nestab_emp_soc$CEP &lt;- sprintf(\"%08d\", as.numeric(trimws(estab_emp_soc$CEP)))\n\n\nCriar uma nova coluna ‘ENDERECO’ unindo ‘TIPO_LOGRADOURO’ e ‘LOGRADOURO’.\n\n\nestab_emp_soc$ENDERECO &lt;- paste(estab_emp_soc$TIPO_LOGRADOURO,\n                                estab_emp_soc$LOGRADOURO)\n\n\nTransformar em inteiro a coluna de N?mero do endereço.\n\n\nestab_emp_soc$NUMERO &lt;- suppressWarnings(as.integer(estab_emp_soc$NUMERO))\n\nGeocodificar Endereços\n\nDefinir os campos para geocodificação.\n\n\ncampos &lt;- geocodebr::definir_campos(\n  estado = \"UF\",\n  municipio = \"MUNICIPIO\",\n  logradouro = \"ENDERECO\",\n  numero = \"NUMERO\",\n  cep = \"CEP\",\n  localidade = \"BAIRRO\"\n)\n\n\nGeocodificar com pacote geocodebr\n\n\nestab_emp_soc_geoloc &lt;- geocodebr::geocode(\n  enderecos = estab_emp_soc,\n  campos_endereco = campos,\n  resultado_completo = TRUE,\n  resultado_sf = FALSE,\n  verboso = TRUE,\n  cache = TRUE,\n  n_cores = 1\n)\n#&gt; ℹ Padronizando endereços de entrada\n#&gt; ℹ Utilizando dados do CNEFE armazenados localmente\n#&gt; ℹ Geolocalizando endereços\n#&gt; Endereços processados: 0/17,395 ■                                  0% - Proc…\n#&gt; \n#&gt; Endereços processados: 3,584/17,395 ■■■■■■■                           21% - …\n#&gt; \n#&gt; Endereços processados: 7,455/17,395 ■■■■■■■■■■■■■■                    43% - …\n#&gt; \n#&gt; Endereços processados: 7,821/17,395 ■■■■■■■■■■■■■■                    45% - …\n#&gt; \n#&gt; Endereços processados: 8,263/17,395 ■■■■■■■■■■■■■■■                   48% - …\n#&gt; \n#&gt; Endereços processados: 11,830/17,395 ■■■■■■■■■■■■■■■■■■■■■             68% -…\n#&gt; \n#&gt; Endereços processados: 14,171/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■         81% -…\n#&gt; \n#&gt; Endereços processados: 14,464/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■        83% -…\n#&gt; \n#&gt; Endereços processados: 14,695/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■        84% -…\n#&gt; \n#&gt; Endereços processados: 15,025/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■       86% -…\n#&gt; \n#&gt; Endereços processados: 15,324/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■       88% -…\n#&gt; \n#&gt; Endereços processados: 15,382/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■      88% -…\n#&gt; \n#&gt; Endereços processados: 15,454/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■      89% -…\n#&gt; \n#&gt; Endereços processados: 15,781/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■      91% -…\n#&gt; \n#&gt; Endereços processados: 15,970/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     92% -…\n#&gt; \n#&gt; Endereços processados: 16,053/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     92% -…\n#&gt; \n#&gt; Endereços processados: 16,062/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     92% -…\n#&gt; \n#&gt; Endereços processados: 16,147/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     93% -…\n#&gt; \n#&gt; Endereços processados: 16,156/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     93% -…\n#&gt; \n#&gt; Endereços processados: 16,162/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     93% -…\n#&gt; \n#&gt; Endereços processados: 16,163/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     93% -…\n#&gt; \n#&gt; Endereços processados: 16,176/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     93% -…\n#&gt; \n#&gt; Endereços processados: 16,498/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     95% -…\n#&gt; \n#&gt; Endereços processados: 17,277/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■   99% -…\n#&gt; \n#&gt; Endereços processados: 17,367/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% -…\n#&gt; \n#&gt; Endereços processados: 17,395/17,395 ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% -…\n#&gt; \n#&gt; \n#&gt; \n#&gt; ℹ Preparando resultados\n#&gt; Warning: Foram encontrados 970 casos de empate. Estes casos foram marcados com valor\n#&gt; `TRUE` na coluna 'empate', e podem ser inspecionados na coluna\n#&gt; 'endereco_encontrado'. Alternativamente, use `resolver_empates = TRUE` para\n#&gt; que o pacote lide com os empates automaticamente. Ver documentação da\n#&gt; função.\n\nbeep()\n\n\nTransformar o data frame de empresas em um objeto sf com coordenadas\n\n\nestab_emp_soc_geom &lt;-\n  estab_emp_soc_geoloc |&gt;\n  st_as_sf(\n    coords = c(\"lon\", \"lat\"),\n    crs = 4326\n  )\n\n\nBaixar arquivos shapefile dos distritos de São Paulo na aba “Layers” http://dados.prefeitura.sp.gov.br/dataset/distritos\n\n\nDefnir caminho do arquivo de distritos\n\n\ndir &lt;- file.path(data_raw_dir, \"LAYER_DISTRITO\")\n\nif (!dir.exists(file.path(dir))) dir.create(dir)\n\n\ndistritos_sp_arquivo_zip &lt;- file.path(\n  data_raw_dir,\n  \"LAYER_DISTRITO\",\n  \"layerdistrito.zip\"\n)\n\n\ndistritos_sp_arquivo_zip |&gt; unzip(exdir = dirname(distritos_sp_arquivo_zip))\n\n\nAbrir o arquivo .shp de distritos em São Paulo.\n\n\ndistritos_sp_arquivo &lt;- file.path(\n  data_raw_dir,\n  \"LAYER_DISTRITO\",\n  \"DEINFO_DISTRITO.shp\"\n)\n\n\nTransformar o shapefile de distritos para o CRS adequado.\n\n\ndistritos_sp &lt;-\n  distritos_sp_arquivo |&gt;\n  st_read() |&gt;\n  st_transform(crs = st_crs(estab_emp_soc_geom))\n#&gt; Reading layer `DEINFO_DISTRITO' from data source \n#&gt;   `/home/danielvartan/Git/acessosan/data-raw/LAYER_DISTRITO/DEINFO_DISTRITO.shp' \n#&gt;   using driver `ESRI Shapefile'\n#&gt; Simple feature collection with 96 features and 9 fields\n#&gt; Geometry type: POLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 313434.77 ymin: 7343788.608 xmax: 360663.2347 ymax: 7416202.047\n#&gt; Projected CRS: SAD69 / UTM zone 23S\n\n\nTransformar COD_DIST em numérica.\n\n\ndistritos_sp$COD_DIST &lt;- as.numeric(distritos_sp$COD_DIST)\n\n\nRealizar a interseção.\n\n\nintersecao &lt;- st_intersects(estab_emp_soc_geom, distritos_sp)\n\n\nAdicionar os dados de distrito.\n\n\nestab_emp_soc_geom &lt;-\n  estab_emp_soc_geom %&gt;%\n  mutate(\n    # Adicionar o nome do distrito ou \"NSA\" caso nao haja interse?ao\n    DISTRITO_SP = map_chr(1:nrow(estab_emp_soc_geom), ~{\n      # Obter o munic?pio para a linha atual\n      municipio &lt;- estab_emp_soc_geom$MUNICIPIO[.x] # Substitua pelo nome correto da coluna do munic?pio\n\n      if (municipio == \"Sao Paulo\") {\n        # Se for Sao Paulo, for?ar a interse?ao com algum distrito\n        distrito &lt;- ifelse(length(intersecao[[.x]]) &gt; 0, distritos_sp$NOME_DIST[intersecao[[.x]][1]], \"NSA\")\n        distrito\n      } else {\n        # Caso contr?rio, usar a l?gica normal de interse?ao\n        if (length(intersecao[[.x]]) &gt; 0) {\n          distritos_sp$NOME_DIST[intersecao[[.x]][1]]\n        } else {\n          \"NSA\"\n        }\n      }\n    }),\n\n    # Adicionar o c?digo do distrito ou \"NSA\"\n    DISTRITO_SP_IBGE = map_chr(1:nrow(estab_emp_soc_geom), ~{\n      municipio &lt;- estab_emp_soc_geom$MUNICIPIO[.x] # Substitua pelo nome correto da coluna do munic?pio\n\n      if (municipio == \"Sao Paulo\") {\n        # Se for Sao Paulo, for?ar a interse?ao com algum distrito\n        distrito_ibge &lt;- ifelse(length(intersecao[[.x]]) &gt; 0, as.character(distritos_sp$COD_DIST[intersecao[[.x]][1]]), \"NSA\")\n        distrito_ibge\n      } else {\n        # Caso contr?rio, usar a l?gica normal de interse?ao\n        if (length(intersecao[[.x]]) &gt; 0) {\n          as.character(distritos_sp$COD_DIST[intersecao[[.x]][1]])\n        } else {\n          \"NSA\"\n        }\n      }\n    })\n  )\n\n  beep()\n\n\nTransformar a geometry em latitude e longitude\n\n\nestab_emp_soc_geom &lt;- estab_emp_soc_geom %&gt;%\n  mutate(lat = st_coordinates(.)[,2],\n         lon = st_coordinates(.)[,1])\n\n\nEscrever o arquivo a partir do dataframe gerado\n\n\nestab_emp_soc_geom |&gt;\n  write_csv(\n    file.path(\n      temporario_dir,\n      \"01.06-geocodificar_enderecos\",\n      \"01.06.01-estab_emp_soc_spcap_farmacias_loc.csv\"\n    )\n  )\n\n\nestab_emp_soc_geom\n\n\n  \n\n\n\n\nbeep(3)"
  },
  {
    "objectID": "index.html#set-the-initial-variables",
    "href": "index.html#set-the-initial-variables",
    "title": "Clara",
    "section": "Set the Initial Variables",
    "text": "Set the Initial Variables"
  },
  {
    "objectID": "index.html#download-the-data",
    "href": "index.html#download-the-data",
    "title": "Clara",
    "section": "Download the Data",
    "text": "Download the Data"
  },
  {
    "objectID": "index.html#read-and-filter-the-data",
    "href": "index.html#read-and-filter-the-data",
    "title": "Clara",
    "section": "Read and Filter the Data",
    "text": "Read and Filter the Data"
  },
  {
    "objectID": "index.html#tidy-the-data",
    "href": "index.html#tidy-the-data",
    "title": "Clara",
    "section": "Tidy the Data",
    "text": "Tidy the Data"
  },
  {
    "objectID": "index.html#transform-the-data",
    "href": "index.html#transform-the-data",
    "title": "Clara",
    "section": "Transform the Data",
    "text": "Transform the Data"
  },
  {
    "objectID": "index.html#validate-the-data",
    "href": "index.html#validate-the-data",
    "title": "Clara",
    "section": "Validate the Data",
    "text": "Validate the Data"
  },
  {
    "objectID": "index.html#arrange-the-data",
    "href": "index.html#arrange-the-data",
    "title": "Clara",
    "section": "Arrange the Data",
    "text": "Arrange the Data"
  },
  {
    "objectID": "index.html#data-dictionary",
    "href": "index.html#data-dictionary",
    "title": "Clara",
    "section": "Data Dictionary",
    "text": "Data Dictionary"
  },
  {
    "objectID": "index.html#save-the-valid-data",
    "href": "index.html#save-the-valid-data",
    "title": "Clara",
    "section": "Save the Valid Data",
    "text": "Save the Valid Data"
  },
  {
    "objectID": "index.html#visualize-the-data",
    "href": "index.html#visualize-the-data",
    "title": "Clara",
    "section": "Visualize the Data",
    "text": "Visualize the Data"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Clara",
    "section": "Citation",
    "text": "Citation"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Clara",
    "section": "License",
    "text": "License\n\n \n\n\n\n\n\n\n\nThe original data sources may have their own license terms and conditions.\n\n\n\nThe code in this report is licensed under the GNU General Public License Version 3, while the report is available under the Creative Commons CC0 License.\nCopyright (C) 2025 Clara Penz & Daniel Vartanian\n\nThe code in this report is free software: you can redistribute it and/or\nmodify it under the terms of the GNU General Public License as published by the\nFree Software Foundation, either version 3 of the License, or (at your option)\nany later version.\n\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY\nWARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE. See the GNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License along with\nthis program. If not, see &lt;https://www.gnu.org/licenses/&gt;."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Clara",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nThis work is part of a research project by the Polytechnic School (Poli) of the University of São Paulo (USP), in partnership with the Secretariat for Food and Nutrition Security ([SESAN(https://www.gov.br/mds/pt-br/orgaos/SESAN)]) of the Ministry of Social Development, Family, and the Fight Against Hunger (MDS): AcessoSAN: Mapping Food Access to Support Public Policies on Food and Nutrition Security and Hunger Reduction in Brazilian Cities.\n\nThis work was developed with support from the Center for Metropolitan Studies (CEM) based at the School of Philosophy, Letters and Human Sciences (FFLCH) of the University of São Paulo (USP) and at the Brazilian Center for Analysis and Planning ([CEBRAP(https://cebrap.org.br/)]).\n\nThis study was financed, in part, by the São Paulo Research Foundation (FAPESP), Brazil. Process Number 2023/10243-0."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Clara",
    "section": "References",
    "text": "References\n\n\nAllaire, J. J., Teague, C., Xie, Y., & Dervieux, C. (n.d.). Quarto [Computer software]. Zenodo. https://doi.org/10.5281/ZENODO.5960048\n\n\nHijmans, R. J. (n.d.). terra: Spatial Data Analysis [Computer software]. https://rspatial.org\n\n\nR Core Team. (n.d.). R: A language and environment for statistical computing [Computer software]. R Foundation for Statistical Computing. https://www.R-project.org\n\n\nWickham, H. (2023). The tidy tools manifesto. Tidyverse. https://tidyverse.tidyverse.org/articles/manifesto.html\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science: Import, tidy, transform, visualize, and model data (2nd ed.). O’Reilly Media. https://r4ds.hadley.nz"
  }
]